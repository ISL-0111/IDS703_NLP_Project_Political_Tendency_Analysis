{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT with LoRA for analysis on political leaning of news; HEADLINE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwAV24NJ-ZSj",
    "outputId": "f707f622-fcd8-4645-fc3f-6beaef291c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/miniconda3/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: peft in /opt/miniconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: evaluate in /opt/miniconda3/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ilseoplee/.local/lib/python3.12/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/miniconda3/lib/python3.12/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/miniconda3/lib/python3.12/site-packages (from peft) (1.1.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C2gg1Syx-s44"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KfUh_vrS_hbR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "# Define label maps\n",
    "id2label = {0: \"UNDEFINED\", 1: \"LEFT\", 2: \"RIGHT\", 3: \"CENTER\"}\n",
    "label2id = {\"UNDEFINED\": 0, \"LEFT\": 1, \"RIGHT\": 2, \"CENTER\": 3}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=4, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Yrj-hSULAi_a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning'],\n",
       "        num_rows: 146718\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = load_dataset(\"csv\", data_files=\"2017_1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_testvalid =\n",
    "df = df[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vKd0MpK9BFPv"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ERySJZcQBp9_"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    text = examples[\"headline\"]\n",
    "    labels = examples[\"political_leaning\"]\n",
    "\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text, return_tensors=\"np\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = [label2id[label] for label in labels]\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YmGXgdNQCb7e"
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZgXdBTYUDLz6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc1796f35634ac2857b7ee4a14561b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/132046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7109e8cd7a4891a131bb1c18216882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14672 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 132046\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14672\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = df.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IjSOWH6wDNHw"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KJvaBgtkD963"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6nP1LQquEmt2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model\n",
      "It was good. - CENTER\n",
      "Not a fan, don't recommended - CENTER\n",
      "Better than the first one. - CENTER\n",
      "Women have the right to choose and abortion should be allowed. - CENTER\n"
     ]
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"It was good.\",\n",
    "    \"Not a fan, don't recommended\",\n",
    "    \"Better than the first one.\",\n",
    "    \"Women have the right to choose and abortion should be allowed.\",\n",
    "]\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Untrained model\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\n",
    "        device\n",
    "    )  # Move inputs to the correct device\n",
    "    logits = model(**inputs).logits  # Forward pass\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    print(f\"{text} - {id2label[predictions.item()]}\")\n",
    "\n",
    "# print(\"Untrained model\")\n",
    "# for text in text_list:\n",
    "#   inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "#   logits = model(inputs).logits\n",
    "#   predictions = torch.argmax(logits)\n",
    "#   print(f'{text} - {id2label[predictions.tolist()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8xiaVnUaF1Yf"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\", r=4, lora_alpha=32, lora_dropout=0.01, target_modules=[\"q_lin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "o4hduUwTGnN5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 630,532 || all params: 67,587,080 || trainable%: 0.9329\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3ORBVjXnGx19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"\" + model_checkpoint + \"lora-txt\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):  #Training\n",
    "    \"\"\"\n",
    "    Computes accuracy, precision, recall, and F1 score.\n",
    "    eval_pred: A tuple of (predictions, labels) provided by the Trainer.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # Convert predictions to the predicted class indices (argmax for softmax outputs)\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hmS4TS65IDDV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/gkxw33gj58n2ptpf02t8_ncr0000gn/T/ipykernel_48645/552906714.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gfzk-YnMJL0V"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52b0d79a51740af9edf50f1aa169bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1826, 'grad_norm': 2.1559102535247803, 'learning_rate': 0.0009924271109428247, 'epoch': 0.04}\n",
      "{'loss': 1.1276, 'grad_norm': 2.546229600906372, 'learning_rate': 0.0009848542218856495, 'epoch': 0.08}\n",
      "{'loss': 1.1081, 'grad_norm': 2.4174036979675293, 'learning_rate': 0.0009772813328284742, 'epoch': 0.11}\n",
      "{'loss': 1.0726, 'grad_norm': 3.5102779865264893, 'learning_rate': 0.0009697084437712988, 'epoch': 0.15}\n",
      "{'loss': 1.0772, 'grad_norm': 2.8828771114349365, 'learning_rate': 0.0009621355547141235, 'epoch': 0.19}\n",
      "{'loss': 1.0928, 'grad_norm': 2.792771100997925, 'learning_rate': 0.0009545626656569481, 'epoch': 0.23}\n",
      "{'loss': 1.07, 'grad_norm': 4.14138650894165, 'learning_rate': 0.0009469897765997728, 'epoch': 0.27}\n",
      "{'loss': 1.0634, 'grad_norm': 2.927995443344116, 'learning_rate': 0.0009394168875425976, 'epoch': 0.3}\n",
      "{'loss': 1.0389, 'grad_norm': 5.25220251083374, 'learning_rate': 0.0009318439984854222, 'epoch': 0.34}\n",
      "{'loss': 1.0532, 'grad_norm': 4.338897228240967, 'learning_rate': 0.0009242711094282469, 'epoch': 0.38}\n",
      "{'loss': 1.0597, 'grad_norm': 3.8896498680114746, 'learning_rate': 0.0009166982203710715, 'epoch': 0.42}\n",
      "{'loss': 1.0608, 'grad_norm': 4.754899978637695, 'learning_rate': 0.0009091253313138963, 'epoch': 0.45}\n",
      "{'loss': 1.0471, 'grad_norm': 3.9043891429901123, 'learning_rate': 0.000901552442256721, 'epoch': 0.49}\n",
      "{'loss': 1.0512, 'grad_norm': 7.178211212158203, 'learning_rate': 0.0008939795531995456, 'epoch': 0.53}\n",
      "{'loss': 1.0631, 'grad_norm': 4.738161087036133, 'learning_rate': 0.0008864066641423704, 'epoch': 0.57}\n",
      "{'loss': 1.0566, 'grad_norm': 11.50511646270752, 'learning_rate': 0.000878833775085195, 'epoch': 0.61}\n",
      "{'loss': 1.0482, 'grad_norm': 3.4171690940856934, 'learning_rate': 0.0008712608860280196, 'epoch': 0.64}\n",
      "{'loss': 1.0525, 'grad_norm': 4.259902477264404, 'learning_rate': 0.0008636879969708444, 'epoch': 0.68}\n",
      "{'loss': 1.0211, 'grad_norm': 3.9101154804229736, 'learning_rate': 0.0008561151079136691, 'epoch': 0.72}\n",
      "{'loss': 1.0441, 'grad_norm': 4.508790016174316, 'learning_rate': 0.0008485422188564938, 'epoch': 0.76}\n",
      "{'loss': 1.0663, 'grad_norm': 3.7389211654663086, 'learning_rate': 0.0008409693297993185, 'epoch': 0.8}\n",
      "{'loss': 1.0272, 'grad_norm': 5.750105857849121, 'learning_rate': 0.0008333964407421431, 'epoch': 0.83}\n",
      "{'loss': 1.0402, 'grad_norm': 6.561656951904297, 'learning_rate': 0.0008258235516849678, 'epoch': 0.87}\n",
      "{'loss': 1.0519, 'grad_norm': 6.086127281188965, 'learning_rate': 0.0008182506626277926, 'epoch': 0.91}\n",
      "{'loss': 1.0249, 'grad_norm': 3.1277577877044678, 'learning_rate': 0.0008106777735706173, 'epoch': 0.95}\n",
      "{'loss': 1.0175, 'grad_norm': 5.342582702636719, 'learning_rate': 0.0008031048845134419, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b36d97d1a9f4365bde65acb8e049ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0168834924697876, 'eval_accuracy': 0.5697928026172301, 'eval_precision': 0.5741508299340383, 'eval_recall': 0.5697928026172301, 'eval_f1': 0.5530911712858528, 'eval_runtime': 31.4472, 'eval_samples_per_second': 466.56, 'eval_steps_per_second': 46.681, 'epoch': 1.0}\n",
      "{'loss': 1.0201, 'grad_norm': 6.383045196533203, 'learning_rate': 0.0007955319954562665, 'epoch': 1.02}\n",
      "{'loss': 1.0194, 'grad_norm': 6.24865198135376, 'learning_rate': 0.0007879591063990913, 'epoch': 1.06}\n",
      "{'loss': 1.0264, 'grad_norm': 3.3156142234802246, 'learning_rate': 0.0007803862173419159, 'epoch': 1.1}\n",
      "{'loss': 1.0159, 'grad_norm': 5.132165908813477, 'learning_rate': 0.0007728133282847406, 'epoch': 1.14}\n",
      "{'loss': 1.032, 'grad_norm': 6.944118022918701, 'learning_rate': 0.0007652404392275654, 'epoch': 1.17}\n",
      "{'loss': 1.0383, 'grad_norm': 6.1990509033203125, 'learning_rate': 0.00075766755017039, 'epoch': 1.21}\n",
      "{'loss': 1.0392, 'grad_norm': 4.666685581207275, 'learning_rate': 0.0007500946611132147, 'epoch': 1.25}\n",
      "{'loss': 1.0231, 'grad_norm': 4.606290340423584, 'learning_rate': 0.0007425217720560394, 'epoch': 1.29}\n",
      "{'loss': 1.0411, 'grad_norm': 5.391127109527588, 'learning_rate': 0.000734948882998864, 'epoch': 1.33}\n",
      "{'loss': 1.0382, 'grad_norm': 9.453710556030273, 'learning_rate': 0.0007273759939416888, 'epoch': 1.36}\n",
      "{'loss': 1.0218, 'grad_norm': 9.186148643493652, 'learning_rate': 0.0007198031048845135, 'epoch': 1.4}\n",
      "{'loss': 1.0191, 'grad_norm': 6.297921180725098, 'learning_rate': 0.0007122302158273382, 'epoch': 1.44}\n",
      "{'loss': 1.0283, 'grad_norm': 5.101146697998047, 'learning_rate': 0.0007046573267701628, 'epoch': 1.48}\n",
      "{'loss': 1.0195, 'grad_norm': 4.36592960357666, 'learning_rate': 0.0006970844377129875, 'epoch': 1.51}\n",
      "{'loss': 1.0418, 'grad_norm': 7.077794551849365, 'learning_rate': 0.0006895115486558123, 'epoch': 1.55}\n",
      "{'loss': 1.0183, 'grad_norm': 5.7988128662109375, 'learning_rate': 0.0006819386595986369, 'epoch': 1.59}\n",
      "{'loss': 1.0132, 'grad_norm': 11.578439712524414, 'learning_rate': 0.0006743657705414615, 'epoch': 1.63}\n",
      "{'loss': 0.9931, 'grad_norm': 6.6720499992370605, 'learning_rate': 0.0006667928814842863, 'epoch': 1.67}\n",
      "{'loss': 1.0107, 'grad_norm': 6.685581207275391, 'learning_rate': 0.0006592199924271109, 'epoch': 1.7}\n",
      "{'loss': 1.0244, 'grad_norm': 7.7307939529418945, 'learning_rate': 0.0006516471033699356, 'epoch': 1.74}\n",
      "{'loss': 1.014, 'grad_norm': 7.672290325164795, 'learning_rate': 0.0006440742143127604, 'epoch': 1.78}\n",
      "{'loss': 1.0067, 'grad_norm': 8.526788711547852, 'learning_rate': 0.000636501325255585, 'epoch': 1.82}\n",
      "{'loss': 1.0153, 'grad_norm': 6.386392116546631, 'learning_rate': 0.0006289284361984097, 'epoch': 1.86}\n",
      "{'loss': 1.0172, 'grad_norm': 4.9605231285095215, 'learning_rate': 0.0006213555471412344, 'epoch': 1.89}\n",
      "{'loss': 1.0047, 'grad_norm': 5.410322666168213, 'learning_rate': 0.000613782658084059, 'epoch': 1.93}\n",
      "{'loss': 1.0261, 'grad_norm': 5.4167962074279785, 'learning_rate': 0.0006062097690268838, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded9728731e34c9594b17e16970c9e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9951158761978149, 'eval_accuracy': 0.5804934569247546, 'eval_precision': 0.5827199270338542, 'eval_recall': 0.5804934569247546, 'eval_f1': 0.572097262717907, 'eval_runtime': 31.0295, 'eval_samples_per_second': 472.841, 'eval_steps_per_second': 47.31, 'epoch': 2.0}\n",
      "{'loss': 1.0114, 'grad_norm': 8.391899108886719, 'learning_rate': 0.0005986368799697085, 'epoch': 2.01}\n",
      "{'loss': 1.0016, 'grad_norm': 4.278904914855957, 'learning_rate': 0.0005910639909125332, 'epoch': 2.04}\n",
      "{'loss': 0.9964, 'grad_norm': 6.008801460266113, 'learning_rate': 0.0005834911018553578, 'epoch': 2.08}\n",
      "{'loss': 0.9869, 'grad_norm': 7.183769226074219, 'learning_rate': 0.0005759182127981825, 'epoch': 2.12}\n",
      "{'loss': 0.978, 'grad_norm': 7.1634907722473145, 'learning_rate': 0.0005683453237410072, 'epoch': 2.16}\n",
      "{'loss': 0.9592, 'grad_norm': 4.88427734375, 'learning_rate': 0.0005607724346838319, 'epoch': 2.2}\n",
      "{'loss': 1.0186, 'grad_norm': 5.267115592956543, 'learning_rate': 0.0005531995456266566, 'epoch': 2.23}\n",
      "{'loss': 1.0198, 'grad_norm': 33.04574203491211, 'learning_rate': 0.0005456266565694813, 'epoch': 2.27}\n",
      "{'loss': 0.9999, 'grad_norm': 9.689020156860352, 'learning_rate': 0.0005380537675123059, 'epoch': 2.31}\n",
      "{'loss': 1.0201, 'grad_norm': 9.451322555541992, 'learning_rate': 0.0005304808784551306, 'epoch': 2.35}\n",
      "{'loss': 1.0008, 'grad_norm': 5.221131801605225, 'learning_rate': 0.0005229079893979554, 'epoch': 2.39}\n",
      "{'loss': 0.9899, 'grad_norm': 4.770535469055176, 'learning_rate': 0.00051533510034078, 'epoch': 2.42}\n",
      "{'loss': 0.9898, 'grad_norm': 6.11933708190918, 'learning_rate': 0.0005077622112836047, 'epoch': 2.46}\n",
      "{'loss': 0.9888, 'grad_norm': 4.385876655578613, 'learning_rate': 0.0005001893222264294, 'epoch': 2.5}\n",
      "{'loss': 0.9862, 'grad_norm': 4.4476399421691895, 'learning_rate': 0.0004926164331692541, 'epoch': 2.54}\n",
      "{'loss': 0.9765, 'grad_norm': 6.106917381286621, 'learning_rate': 0.0004850435441120788, 'epoch': 2.57}\n",
      "{'loss': 0.9869, 'grad_norm': 5.634596347808838, 'learning_rate': 0.00047747065505490346, 'epoch': 2.61}\n",
      "{'loss': 0.9884, 'grad_norm': 3.7697842121124268, 'learning_rate': 0.00046989776599772813, 'epoch': 2.65}\n",
      "{'loss': 0.97, 'grad_norm': 5.453227996826172, 'learning_rate': 0.0004623248769405528, 'epoch': 2.69}\n",
      "{'loss': 0.9884, 'grad_norm': 3.8309760093688965, 'learning_rate': 0.0004547519878833775, 'epoch': 2.73}\n",
      "{'loss': 0.96, 'grad_norm': 4.996708393096924, 'learning_rate': 0.00044717909882620224, 'epoch': 2.76}\n",
      "{'loss': 0.9837, 'grad_norm': 5.604050159454346, 'learning_rate': 0.0004396062097690269, 'epoch': 2.8}\n",
      "{'loss': 0.9759, 'grad_norm': 6.45932674407959, 'learning_rate': 0.00043203332071185157, 'epoch': 2.84}\n",
      "{'loss': 0.988, 'grad_norm': 4.104434013366699, 'learning_rate': 0.0004244604316546763, 'epoch': 2.88}\n",
      "{'loss': 0.9765, 'grad_norm': 6.400765895843506, 'learning_rate': 0.00041688754259750096, 'epoch': 2.92}\n",
      "{'loss': 0.9953, 'grad_norm': 4.6550374031066895, 'learning_rate': 0.0004093146535403257, 'epoch': 2.95}\n",
      "{'loss': 0.9742, 'grad_norm': 4.570581436157227, 'learning_rate': 0.0004017417644831503, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98c304ffb204c309ab2f5ad35a4019d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.932221531867981, 'eval_accuracy': 0.6040076335877863, 'eval_precision': 0.6039375909284557, 'eval_recall': 0.6040076335877863, 'eval_f1': 0.5994331072176401, 'eval_runtime': 30.499, 'eval_samples_per_second': 481.064, 'eval_steps_per_second': 48.133, 'epoch': 3.0}\n",
      "{'loss': 0.9686, 'grad_norm': 4.214250087738037, 'learning_rate': 0.000394168875425975, 'epoch': 3.03}\n",
      "{'loss': 0.9536, 'grad_norm': 5.479396343231201, 'learning_rate': 0.00038659598636879973, 'epoch': 3.07}\n",
      "{'loss': 0.94, 'grad_norm': 3.582141399383545, 'learning_rate': 0.0003790230973116244, 'epoch': 3.1}\n",
      "{'loss': 0.9495, 'grad_norm': 7.096805572509766, 'learning_rate': 0.00037145020825444906, 'epoch': 3.14}\n",
      "{'loss': 0.9477, 'grad_norm': 5.46033239364624, 'learning_rate': 0.0003638773191972738, 'epoch': 3.18}\n",
      "{'loss': 0.9364, 'grad_norm': 3.569082021713257, 'learning_rate': 0.00035630443014009845, 'epoch': 3.22}\n",
      "{'loss': 0.9522, 'grad_norm': 4.834888935089111, 'learning_rate': 0.00034873154108292317, 'epoch': 3.26}\n",
      "{'loss': 0.9427, 'grad_norm': 4.592099666595459, 'learning_rate': 0.0003411586520257478, 'epoch': 3.29}\n",
      "{'loss': 0.9352, 'grad_norm': 4.86850643157959, 'learning_rate': 0.0003335857629685725, 'epoch': 3.33}\n",
      "{'loss': 0.953, 'grad_norm': 3.8952994346618652, 'learning_rate': 0.0003260128739113972, 'epoch': 3.37}\n",
      "{'loss': 0.9609, 'grad_norm': 3.407595634460449, 'learning_rate': 0.0003184399848542219, 'epoch': 3.41}\n",
      "{'loss': 0.9458, 'grad_norm': 6.46713924407959, 'learning_rate': 0.0003108670957970466, 'epoch': 3.45}\n",
      "{'loss': 0.9374, 'grad_norm': 4.4598002433776855, 'learning_rate': 0.0003032942067398713, 'epoch': 3.48}\n",
      "{'loss': 0.9593, 'grad_norm': 3.821974039077759, 'learning_rate': 0.00029572131768269594, 'epoch': 3.52}\n",
      "{'loss': 0.9483, 'grad_norm': 6.271103858947754, 'learning_rate': 0.00028814842862552066, 'epoch': 3.56}\n",
      "{'loss': 0.9329, 'grad_norm': 5.503909111022949, 'learning_rate': 0.00028057553956834533, 'epoch': 3.6}\n",
      "{'loss': 0.9431, 'grad_norm': 4.485729217529297, 'learning_rate': 0.00027300265051117, 'epoch': 3.63}\n",
      "{'loss': 0.9322, 'grad_norm': 3.0463950634002686, 'learning_rate': 0.0002654297614539947, 'epoch': 3.67}\n",
      "{'loss': 0.9093, 'grad_norm': 4.202706336975098, 'learning_rate': 0.0002578568723968194, 'epoch': 3.71}\n",
      "{'loss': 0.9294, 'grad_norm': 3.8709943294525146, 'learning_rate': 0.0002502839833396441, 'epoch': 3.75}\n",
      "{'loss': 0.9282, 'grad_norm': 4.991508960723877, 'learning_rate': 0.00024271109428246877, 'epoch': 3.79}\n",
      "{'loss': 0.9093, 'grad_norm': 3.906285047531128, 'learning_rate': 0.00023513820522529344, 'epoch': 3.82}\n",
      "{'loss': 0.9077, 'grad_norm': 8.179913520812988, 'learning_rate': 0.00022756531616811816, 'epoch': 3.86}\n",
      "{'loss': 0.9244, 'grad_norm': 4.609148025512695, 'learning_rate': 0.00021999242711094282, 'epoch': 3.9}\n",
      "{'loss': 0.9189, 'grad_norm': 3.5823190212249756, 'learning_rate': 0.00021241953805376752, 'epoch': 3.94}\n",
      "{'loss': 0.9141, 'grad_norm': 3.8988006114959717, 'learning_rate': 0.00020484664899659218, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9449f73dec124289b87f875da46bec5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9141486287117004, 'eval_accuracy': 0.6138222464558343, 'eval_precision': 0.6140510228721306, 'eval_recall': 0.6138222464558343, 'eval_f1': 0.6060873913924246, 'eval_runtime': 29.7338, 'eval_samples_per_second': 493.446, 'eval_steps_per_second': 49.372, 'epoch': 4.0}\n",
      "{'loss': 0.9061, 'grad_norm': 4.245834827423096, 'learning_rate': 0.0001972737599394169, 'epoch': 4.01}\n",
      "{'loss': 0.9036, 'grad_norm': 5.381833076477051, 'learning_rate': 0.0001897008708822416, 'epoch': 4.05}\n",
      "{'loss': 0.8732, 'grad_norm': 3.8634862899780273, 'learning_rate': 0.00018212798182506626, 'epoch': 4.09}\n",
      "{'loss': 0.8932, 'grad_norm': 4.223770618438721, 'learning_rate': 0.00017455509276789096, 'epoch': 4.13}\n",
      "{'loss': 0.9099, 'grad_norm': 2.003406286239624, 'learning_rate': 0.00016698220371071565, 'epoch': 4.17}\n",
      "{'loss': 0.9164, 'grad_norm': 3.672020673751831, 'learning_rate': 0.00015940931465354034, 'epoch': 4.2}\n",
      "{'loss': 0.8881, 'grad_norm': 7.169710159301758, 'learning_rate': 0.000151836425596365, 'epoch': 4.24}\n",
      "{'loss': 0.9129, 'grad_norm': 3.6454694271087646, 'learning_rate': 0.0001442635365391897, 'epoch': 4.28}\n",
      "{'loss': 0.8951, 'grad_norm': 4.201272487640381, 'learning_rate': 0.0001366906474820144, 'epoch': 4.32}\n",
      "{'loss': 0.8881, 'grad_norm': 4.155215263366699, 'learning_rate': 0.0001291177584248391, 'epoch': 4.35}\n",
      "{'loss': 0.888, 'grad_norm': 3.930438995361328, 'learning_rate': 0.00012154486936766377, 'epoch': 4.39}\n",
      "{'loss': 0.8848, 'grad_norm': 4.526027202606201, 'learning_rate': 0.00011397198031048846, 'epoch': 4.43}\n",
      "{'loss': 0.8874, 'grad_norm': 7.091756820678711, 'learning_rate': 0.00010639909125331314, 'epoch': 4.47}\n",
      "{'loss': 0.898, 'grad_norm': 3.9020814895629883, 'learning_rate': 9.882620219613784e-05, 'epoch': 4.51}\n",
      "{'loss': 0.8769, 'grad_norm': 3.101707696914673, 'learning_rate': 9.125331313896252e-05, 'epoch': 4.54}\n",
      "{'loss': 0.8885, 'grad_norm': 5.980100154876709, 'learning_rate': 8.368042408178721e-05, 'epoch': 4.58}\n",
      "{'loss': 0.8753, 'grad_norm': 4.246558666229248, 'learning_rate': 7.610753502461189e-05, 'epoch': 4.62}\n",
      "{'loss': 0.8808, 'grad_norm': 4.206765651702881, 'learning_rate': 6.853464596743658e-05, 'epoch': 4.66}\n",
      "{'loss': 0.9089, 'grad_norm': 7.30296516418457, 'learning_rate': 6.096175691026127e-05, 'epoch': 4.7}\n",
      "{'loss': 0.9046, 'grad_norm': 4.907427787780762, 'learning_rate': 5.3388867853085956e-05, 'epoch': 4.73}\n",
      "{'loss': 0.8816, 'grad_norm': 6.162168979644775, 'learning_rate': 4.581597879591064e-05, 'epoch': 4.77}\n",
      "{'loss': 0.888, 'grad_norm': 3.3320395946502686, 'learning_rate': 3.824308973873533e-05, 'epoch': 4.81}\n",
      "{'loss': 0.8943, 'grad_norm': 2.8144822120666504, 'learning_rate': 3.0670200681560016e-05, 'epoch': 4.85}\n",
      "{'loss': 0.8717, 'grad_norm': 2.583409070968628, 'learning_rate': 2.3097311624384703e-05, 'epoch': 4.88}\n",
      "{'loss': 0.9043, 'grad_norm': 2.6944580078125, 'learning_rate': 1.552442256720939e-05, 'epoch': 4.92}\n",
      "{'loss': 0.8755, 'grad_norm': 3.704437494277954, 'learning_rate': 7.951533510034078e-06, 'epoch': 4.96}\n",
      "{'loss': 0.8692, 'grad_norm': 4.443080425262451, 'learning_rate': 3.786444528587656e-07, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37703843b75b4b2da60a7db270cbbd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8931793570518494, 'eval_accuracy': 0.6250681570338059, 'eval_precision': 0.6236362289471225, 'eval_recall': 0.6250681570338059, 'eval_f1': 0.6187832168640847, 'eval_runtime': 30.368, 'eval_samples_per_second': 483.14, 'eval_steps_per_second': 48.34, 'epoch': 5.0}\n",
      "{'train_runtime': 2374.8099, 'train_samples_per_second': 278.014, 'train_steps_per_second': 27.802, 'train_loss': 0.9798310379438534, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=66025, training_loss=0.9798310379438534, metrics={'train_runtime': 2374.8099, 'train_samples_per_second': 278.014, 'train_steps_per_second': 27.802, 'total_flos': 1.0172928909681888e+16, 'train_loss': 0.9798310379438534, 'epoch': 5.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0jn1iHMyJNtM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Trained model predictions\n",
      "It was good. - LEFT\n",
      "Not a fan, don't recommended - LEFT\n",
      "Better than the first one. - LEFT\n",
      "Women have the right to choose and abortion should be allowed. - LEFT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Trained model predictions\")\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    print(f\"{text} - {id2label[predictions.item()]}\")\n",
    "\n",
    "\n",
    "# INITIAL CODE\n",
    "# model.to('cuda')\n",
    "# print('Trained model predictions')\n",
    "# for text in text_list:\n",
    "#   inputs = tokenizer.encode(text, return_tensors='pt').to('cuda')\n",
    "\n",
    "#   logits = model(inputs).logits\n",
    "#   predictions = torch.max(logits,1).indices\n",
    "\n",
    "#   print(f'{text} - {id2label[predictions.tolist()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OQ9UjA-nLGzS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n"
     ]
    }
   ],
   "source": [
    "output_model_file = \"pytorch_distilbert_imbd.bin\"\n",
    "output_vocab_file = \"vocab_distilbert_imbd.bin\"\n",
    "\n",
    "# Save model\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "\n",
    "# Save tokenizer vocabulary in the current directory\n",
    "tokenizer.save_vocabulary(\".\")  # Current directory\n",
    "\n",
    "# Save model state dictionary\n",
    "torch.save(model.state_dict(), \"LORA_distilBERT_HEAD_2017_1.pth\")\n",
    "\n",
    "print(\"All files saved\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
