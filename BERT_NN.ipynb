{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2sMmlrTBL6W"
   },
   "source": [
    "# Alejandro Paredes, Parameter tuning of BERT\n",
    "\n",
    "https://arunm8489.medium.com/understanding-distil-bert-in-depth-5f2ca92cf1ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pNpc6KmBRY4",
    "outputId": "a02a3279-1b48-48b8-da39-8402311f6642"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwAV24NJ-ZSj",
    "outputId": "ca33db64-8fcd-4613-f9d9-dba631f74faa"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers datasets peft evaluate datasets contractions tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "C2gg1Syx-s44",
    "outputId": "eb798168-37c2-45d0-e18b-69982ec24a05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DistilBertModel,\n",
    "    DistilBertTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yrj-hSULAi_a",
    "outputId": "c2c054b0-7912-4250-f086-488b4b093400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning'],\n",
       "        num_rows: 117374\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning'],\n",
       "        num_rows: 29344\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load all CSV files in the ./data directory\n",
    "#data_files = \"./data/*.csv\"\n",
    "\n",
    "# Load and combine the datasets\n",
    "dataset = load_dataset(\"csv\", data_files=\"./data/2017_1.csv\")#data_files)\n",
    "\n",
    "# Filter and split the dataset\n",
    "df  = dataset['train'].filter(\n",
    "    lambda example: example['headline'] is not None and example['headline'].strip() != ''\n",
    ").train_test_split(test_size=0.2)\n",
    "\n",
    "# Display the resulting dataset\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "_8Wqw02VBL6f"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "#Define label maps\n",
    "id2label = {0:\"UNDEFINED\" ,1:\"LEFT\",2:\"RIGHT\",3:\"CENTER\"}\n",
    "label2id = {\"UNDEFINED\": 0, \"LEFT\": 1, \"RIGHT\": 2, \"CENTER\": 3}\n",
    "\n",
    "tokenizer =  DistilBertTokenizer.from_pretrained(model_checkpoint, add_prefix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "r1fchlLlBL6g"
   },
   "outputs": [],
   "source": [
    "#lemmatization and removing stopwords\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.SMILEY)\n",
    "\n",
    "def preprocess(text):\n",
    "    def is_english_word(word):\n",
    "        \"\"\"Function to filter out non-English words.\"\"\"\n",
    "        return bool(re.match(r'^[a-zA-Z]+$', word))\n",
    "    text = text.lower()\n",
    "    text = contractions.fix(text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = p.clean(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKd0MpK9BFPv",
    "outputId": "82415701-c8f9-4104-a2e0-91c50eee79a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Escondida copper mine strikers and BHP agree to meet \n",
      "\n",
      "Tokenized Text:  ['es', '##con', '##di', '##da', 'copper', 'mine', 'strikers', 'and', 'bhp', 'agree', 'to', 'meet'] \n",
      "\n",
      "Token IDs:  [9686, 8663, 4305, 2850, 6967, 3067, 26049, 1998, 22245, 5993, 2000, 3113]\n",
      "Original Text:  Uber Exec Fired After Sharing Woman's Medical Records Who Was Raped by Driver \n",
      "\n",
      "Tokenized Text:  ['uber', 'ex', '##ec', 'fired', 'after', 'sharing', 'woman', \"'\", 's', 'medical', 'records', 'who', 'was', 'raped', 'by', 'driver'] \n",
      "\n",
      "Token IDs:  [19169, 4654, 8586, 5045, 2044, 6631, 2450, 1005, 1055, 2966, 2636, 2040, 2001, 15504, 2011, 4062]\n",
      "Original Text:  EPA won't ban pesticide chlorpyrifos; is it safe? \n",
      "\n",
      "Tokenized Text:  ['epa', 'will', 'not', 'ban', 'pest', '##icide', 'ch', '##lor', '##py', '##ri', '##fo', '##s', ';', 'is', 'it', 'safe', '?'] \n",
      "\n",
      "Token IDs:  [19044, 2180, 1005, 1056, 7221, 20739, 21752, 10381, 10626, 7685, 3089, 14876, 2015, 1025, 2003, 2009, 3647, 1029]\n",
      "Original Text:  U.S. property loans grew 5.8 percent in 2016: MBA \n",
      "\n",
      "Tokenized Text:  ['you', '.', 's', '.', 'property', 'loans', 'grew', '5', '.', '8', 'percent', 'in', '2016', ':', 'mba'] \n",
      "\n",
      "Token IDs:  [1057, 1012, 1055, 1012, 3200, 10940, 3473, 1019, 1012, 1022, 3867, 1999, 2355, 1024, 15038]\n",
      "Original Text:  Jeff Sessions defended by conservative media. \n",
      "\n",
      "Tokenized Text:  ['jeff', 'sessions', 'defended', 'by', 'conservative', 'media', '.'] \n",
      "\n",
      "Token IDs:  [5076, 6521, 8047, 2011, 4603, 2865, 1012]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Original Text: ', df['train']['headline'][i], '\\n')\n",
    "    print('Tokenized Text: ', tokenizer.tokenize(preprocess(df['train']['headline'][i])), '\\n')\n",
    "    print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df['train']['headline'][i])))\n",
    "\n",
    "#for i in range(2):\n",
    "    #print('Original Text: ', df['train']['body'][i], '\\n')\n",
    "    #print('Tokenized Text: ', tokenizer.tokenize(preprocess(df['train']['body'][i])), '\\n')\n",
    "    #print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df['train']['body'][i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B99-PUpHBL6i",
    "outputId": "2236512c-c887-4f9c-bb2d-3bca43abec77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline Lengths\n",
      "min 1\n",
      "max 40\n",
      "records with more thatn 300 words: 0\n",
      "Body Lengths\n",
      "min 15\n",
      "max 17700\n",
      "records with more thatn 300 words: 77621\n"
     ]
    }
   ],
   "source": [
    "texts = df['train']['headline']\n",
    "\n",
    "# Handle None or missing values by filtering out None entries\n",
    "text_lengths = [len(text.split(' ')) if text is not None else 0 for text in texts]\n",
    "print(\"Headline Lengths\")\n",
    "print(\"min\", min(text_lengths))\n",
    "print(\"max\", max(text_lengths))\n",
    "\n",
    "# Count how many texts have 300 or more words\n",
    "print(\"records with more thatn 300 words:\", sum([1 for length in text_lengths if length >= 300]))\n",
    "\n",
    "# Repeat for the 'body' column\n",
    "texts = df['train']['body']\n",
    "\n",
    "# Handle None or missing values by filtering out None entries\n",
    "text_lengths = [len(text.split()) if text is not None else 0 for text in texts]\n",
    "print(\"Body Lengths\")\n",
    "print(\"min\", min(text_lengths))\n",
    "print(\"max\",max(text_lengths))\n",
    "\n",
    "# Count how many texts have 300 or more words\n",
    "print(\"records with more thatn 300 words:\", sum([1 for length in text_lengths if length >= 300]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWWgLAscBL6j"
   },
   "source": [
    "# **Creating a custom model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "k0vbHLyjBL6j"
   },
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
    "\n",
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(model_checkpoint, num_labels=4)\n",
    "\n",
    "        # Freeze DistilBERT parameters\n",
    "        for param in self.l1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.fc1 = torch.nn.Linear(768, 1024)  # Input dimension is 768 for BERT\n",
    "        #self.fc2 = torch.nn.Linear(1024, 512)\n",
    "        self.classifier = torch.nn.Linear(1024, 4)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        pooler = self.fc1(pooler)\n",
    "        pooler = self.relu(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        #pooler = self.fc2(pooler)\n",
    "        #pooler = self.relu(pooler)\n",
    "        #pooler = self.dropout(pooler)\n",
    "        #pooler = self.fc3(pooler)\n",
    "        #pooler = self.softmax(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data imbalance\n",
    "\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import pandas as pd\n",
    "df_expection = pd.read_csv('./data/2017_1.csv')\n",
    "\n",
    "df_expection.political_leaning.value_counts()\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(df_expection['political_leaning']), y=df_expection['political_leaning'])\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "#class_weights_dict = dict(zip(np.unique(df_expection['political_leaning']), class_weights))\n",
    "# Convert class weights into a tensor\n",
    "#weights = torch.tensor([class_weights_dict[label] for label in df_expection['political_leaning']])\n",
    "#sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjBjQXj4BL6j",
    "outputId": "5e40bd38-b4d1-4dc0-e6fc-5527e3faea3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (fc1): Linear(in_features=768, out_features=1024, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 10\n",
    "VALID_BATCH_SIZE = 10\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-04\n",
    "\n",
    "model = DistillBERTClass()\n",
    "model.to(device)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights.to(device),reduction='mean')\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.4)\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUWKDy2QBL6k",
    "outputId": "0e2e9bed-41a3-4608-b03c-36896aaf047b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1.embeddings.word_embeddings.weight: requires_grad=False\n",
      "l1.embeddings.position_embeddings.weight: requires_grad=False\n",
      "l1.embeddings.LayerNorm.weight: requires_grad=False\n",
      "l1.embeddings.LayerNorm.bias: requires_grad=False\n",
      "l1.transformer.layer.0.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.0.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.0.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.0.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.0.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.0.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.0.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.0.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.0.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.0.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.0.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.0.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.0.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.0.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.0.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.0.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.1.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.1.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.1.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.1.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.1.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.1.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.1.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.1.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.1.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.1.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.1.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.1.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.1.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.1.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.1.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.1.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.2.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.2.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.2.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.2.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.2.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.2.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.2.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.2.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.2.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.2.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.2.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.2.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.2.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.2.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.2.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.2.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.3.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.3.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.3.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.3.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.3.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.3.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.3.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.3.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.3.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.3.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.3.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.3.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.3.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.3.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.3.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.3.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.4.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.4.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.4.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.4.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.4.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.4.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.4.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.4.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.4.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.4.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.4.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.4.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.4.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.4.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.4.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.4.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.5.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.5.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.5.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.5.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.5.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.5.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.5.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.5.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.5.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.5.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.5.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.5.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.5.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.5.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.5.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.5.output_layer_norm.bias: requires_grad=False\n",
      "pre_classifier.weight: requires_grad=True\n",
      "pre_classifier.bias: requires_grad=True\n",
      "fc1.weight: requires_grad=True\n",
      "fc1.bias: requires_grad=True\n",
      "classifier.weight: requires_grad=True\n",
      "classifier.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "YmGXgdNQCb7e"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "  model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "ZgXdBTYUDLz6"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    #text = examples[\"body\"]\n",
    "    text = examples[\"body\"]\n",
    "    labels = examples[\"political_leaning\"]\n",
    "\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,#[preprocess(t) for t in text] ,\n",
    "        return_tensors = \"np\",\n",
    "        #padding = True,\n",
    "        truncation = True,\n",
    "        max_length = 512\n",
    "        )\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = [label2id[label] for label in labels]\n",
    "    return tokenized_inputs\n",
    "\n",
    "#tokenized_dataset = df.map(tokenize_function, batched=True)\n",
    "#tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "Vf28kN8fBL6l"
   },
   "outputs": [],
   "source": [
    "# Define split ratio for validation\n",
    "train_test_split = df[\"train\"].train_test_split(test_size=0.1)  # 10% for validation\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_test_split[\"train\"],\n",
    "    \"validation\": train_test_split[\"test\"],  # This is your validation set\n",
    "    \"test\": df[\"test\"],       # Keep the original test set\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "_4hEof0NBL6l"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    \"\"\" Preprocess the text to clean it for tokenization \"\"\"\n",
    "    def is_english_word(word):\n",
    "        \"\"\"Function to filter out non-English words.\"\"\"\n",
    "        return bool(re.match(r'^[a-zA-Z]+$', word))\n",
    "\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = contractions.fix(text)  # Expand contractions (e.g., \"don't\" -> \"do not\")\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
    "    text = p.clean(text)  # Clean text using the clean-text library\n",
    "    return text\n",
    "\n",
    "class Triage(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length):\n",
    "        self.texts = dataset['body']  # Assuming 'text' column contains the raw text\n",
    "        self.labels = dataset['political_leaning']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.document_id = dataset['id']\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get raw text and label for the current index\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        tokenizer.truncation_side = \"left\"\n",
    "        #tokenized_inputs = self.tokenizer(\n",
    "        tokenized_inputs = self.tokenizer.encode_plus(\n",
    "            preprocess(text),\n",
    "            None,\n",
    "            #return_tensors=\"pt\",\n",
    "            #padding=True,\n",
    "            truncation=True,\n",
    "            #max_length=self.max_length\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_max_length=True\n",
    "        )\n",
    "\n",
    "        #encoding = tokenize_function({\"text\": [text], \"labels\": [label]}, self.tokenizer, self.max_length)\n",
    "        input_ids = tokenized_inputs['input_ids']  # Remove the batch dimension\n",
    "        attention_mask = tokenized_inputs['attention_mask']  # Remove the batch dimension\n",
    "\n",
    "        return {\n",
    "            'document_id': self.document_id[index],\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(label2id[self.labels[index]], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "mvrU6xHpBL6l"
   },
   "outputs": [],
   "source": [
    "train_dataset = Triage(datasets['train'], tokenizer, max_length=512)\n",
    "val_dataset = Triage(datasets['validation'], tokenizer, max_length=512)\n",
    "test_dataset = Triage(datasets['test'], tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "On3GSFT7BL6l"
   },
   "outputs": [],
   "source": [
    "# Training DataLoader\n",
    "training_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation DataLoader\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# Test DataLoader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iR8md4S6BL6m"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "o4hduUwTGnN5"
   },
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "def calculate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)#, token_type_ids)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calculate_accuracy(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "\n",
    "        if _%500==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples\n",
    "            print(f\"Training Loss per 500 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 500 steps: {accu_step}\")\n",
    "            with open(\"./results/v5/step_results.txt\", \"a\") as file:\n",
    "                file.write(f\"{loss_step}|{accu_step}\\n\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return epoch_loss, epoch_accu\n",
    "\n",
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['labels'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask).squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calculate_accuracy(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "\n",
    "            if _%5000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return epoch_loss, epoch_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kupJM6s-BL6m",
    "outputId": "4c9b160c-c896-49ea-ef79-df30aa362096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]c:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "1it [00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.4242361783981323\n",
      "Training Accuracy per 500 steps: 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:31,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.293851233290103\n",
      "Training Accuracy per 500 steps: 44.550898203592816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:02,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.2571356030968162\n",
      "Training Accuracy per 500 steps: 48.24175824175824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [07:31,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.235605181534238\n",
      "Training Accuracy per 500 steps: 50.066622251832115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [10:03,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.2202215864919295\n",
      "Training Accuracy per 500 steps: 51.51424287856072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [12:37,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.2076833093704962\n",
      "Training Accuracy per 500 steps: 52.982806877249104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [15:09,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.199284334454446\n",
      "Training Accuracy per 500 steps: 53.73542152615795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3501it [17:42,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1903534421611601\n",
      "Training Accuracy per 500 steps: 54.712939160239934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [20:18,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1841151324012107\n",
      "Training Accuracy per 500 steps: 55.31867033241689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4501it [22:51,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1776242948086943\n",
      "Training Accuracy per 500 steps: 55.9164630082204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [25:21,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1729677703184644\n",
      "Training Accuracy per 500 steps: 56.41071785642871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5501it [27:55,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1695660697050776\n",
      "Training Accuracy per 500 steps: 56.6915106344301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [30:27,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.165479133157328\n",
      "Training Accuracy per 500 steps: 57.10548241959673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6501it [32:59,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1615713526883173\n",
      "Training Accuracy per 500 steps: 57.532687278880175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [35:31,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1578358575593164\n",
      "Training Accuracy per 500 steps: 57.924582202542496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7501it [38:03,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1543525414710967\n",
      "Training Accuracy per 500 steps: 58.296227169710704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [40:37,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1520563872839984\n",
      "Training Accuracy per 500 steps: 58.5076865391826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8501it [43:09,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1492112242618795\n",
      "Training Accuracy per 500 steps: 58.7954358310787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [45:39,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.146772513673274\n",
      "Training Accuracy per 500 steps: 59.026774802799686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9501it [48:10,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1447154525806622\n",
      "Training Accuracy per 500 steps: 59.221134617408694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [50:42,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1427433004427905\n",
      "Training Accuracy per 500 steps: 59.398060193980605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10501it [53:15,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1412762477561162\n",
      "Training Accuracy per 500 steps: 59.54385296638415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10564it [53:35,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 59.58101404824113\n",
      "Training Loss Epoch: 1.1409030651637706\n",
      "Training Accuracy Epoch: 59.58101404824113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss per 100 steps: 1.0125705003738403\n",
      "Validation Accuracy per 100 steps: 70.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1174it [06:04,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 1.0950393008109456\n",
      "Validation Accuracy Epoch: 63.58834554438575\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./models/local_run_BERT_body_v5 does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n\u001b[0;32m     27\u001b[0m     best_val_loss \u001b[38;5;241m=\u001b[39m val_loss\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/local_run_BERT_body_v5/best_model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved Best Model!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_accuracy \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m91\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\torch\\serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    850\u001b[0m         _save(\n\u001b[0;32m    851\u001b[0m             obj,\n\u001b[0;32m    852\u001b[0m             opened_zipfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[0;32m    856\u001b[0m         )\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\torch\\serialization.py:716\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\torch\\serialization.py:687\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory ./models/local_run_BERT_body_v5 does not exist."
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "#checkpoint = torch.load(\"./models/local_run_BERT_body_v3/best_model.pt\")\n",
    "#print(checkpoint.keys())\n",
    "#model.load_state_dict(checkpoint)\n",
    "\n",
    "# Open a file to write the results\n",
    "with open(\"./results/v5/training_results.txt\", \"w\") as file:\n",
    "    # Writing headers to the file\n",
    "    file.write(\"Epoch|Training Loss|Training Accuracy|Validation Loss|Validation Accuracy\\n\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        epoch_loss, epoch_accu = train(epoch)\n",
    "        val_loss, val_accuracy = valid(model, val_loader)\n",
    "\n",
    "        # Write the results to the file\n",
    "        file.write(f\"{epoch + 1}|{epoch_loss:.4f}|{epoch_accu:.4f}|{val_loss:.4f}|{val_accuracy:.4f}\\n\")\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(\"Learning rate:\", param_group['lr'])\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"./models/local_run_BERT_body_v5/best_model.pt\")\n",
    "            print(\"Saved Best Model!\")\n",
    "\n",
    "        if val_accuracy > 91:\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "print(\"Training results saved to 'training_results.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/local_run_BERT_body_v4/vocab.txt',)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_vocabulary('./models/local_run_BERT_body_v4/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oETAzaqeBL6m",
    "outputId": "6582bbc4-d9a8-4565-f51e-6a6d9e116941"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALEJANDRO\\AppData\\Local\\Temp\\ipykernel_20056\\1796516872.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./models/local_run_BERT_body_v4/best_model.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (fc1): Linear(in_features=768, out_features=1024, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./models/local_run_BERT_body_v4/best_model.pt\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxTWh0CZBL6n",
    "outputId": "4a835e32-f0a2-4322-8d33-2ea54f5d937d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 917/917 [20:26<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results\n",
      "------------------------------\n",
      "Accuracy: 0.6193\n",
      "Precision: 0.5507\n",
      "Recall: 0.6193\n",
      "F1-score: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Test function\n",
    "def test_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Testing\"):\n",
    "            # Move batch to GPU/CPU\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Collect predictions and true labels\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "    print(\"\\nTest Results\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# After training and validation, evaluate on the test set\n",
    "print(\"\\nEvaluating on Test Set\")\n",
    "test_accuracy, test_precision, test_recall, test_f1 = test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "PcInvd2hBL6n",
    "outputId": "9cb360f6-bc53-4553-d6a5-dac5225290a6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot function for metrics\n",
    "def plot_metrics(metrics, metric_names, title):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    bars = ax.bar(metric_names, metrics, color=['skyblue', 'orange', 'green', 'red'])\n",
    "\n",
    "    # Add value annotations on bars\n",
    "    for bar in bars:\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,\n",
    "                f\"{bar.get_height():.4f}\", ha='center', fontsize=10)\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_ylabel(\"Score\", fontsize=14)\n",
    "    ax.set_xlabel(\"Metrics\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "# After testing, plot the metrics\n",
    "#print(\"\\nEvaluating on Test Set\")\n",
    "#test_accuracy, test_precision, test_recall, test_f1 = test_model(model, test_loader, device)\n",
    "\n",
    "# Metrics and their names\n",
    "metrics = [test_accuracy, test_precision, test_recall, test_f1]\n",
    "metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "# Plot the test results\n",
    "plot_metrics(metrics, metric_names, title=\"Test Metrics Overview\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmxsoKs4C1yh"
   },
   "source": [
    "# **Metrics by class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/1468 [00:00<?, ?it/s]c:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Testing: 100%|| 1468/1468 [11:43<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv\n",
      "\n",
      "Test Results\n",
      "------------------------------\n",
      "Overall Accuracy: 0.6193\n",
      "\n",
      "Class: UNDEFINED\n",
      "  Accuracy: 0.5801\n",
      "  Precision: 0.6498\n",
      "  Recall: 0.5801\n",
      "  F1-Score: 0.6130\n",
      "\n",
      "Class: LEFT\n",
      "  Accuracy: 0.6846\n",
      "  Precision: 0.6407\n",
      "  Recall: 0.6846\n",
      "  F1-Score: 0.6619\n",
      "\n",
      "Class: RIGHT\n",
      "  Accuracy: 0.0000\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-Score: 0.0000\n",
      "\n",
      "Class: CENTER\n",
      "  Accuracy: 0.8185\n",
      "  Precision: 0.5880\n",
      "  Recall: 0.8185\n",
      "  F1-Score: 0.6844\n",
      "\n",
      "Test Results from CSV\n",
      "Overall Accuracy: 0.6193\n",
      "\n",
      "Class: UNDEFINED\n",
      "  Precision: 0.6498\n",
      "  Recall: 0.5801\n",
      "  F1-Score: 0.6130\n",
      "\n",
      "Class: LEFT\n",
      "  Precision: 0.6407\n",
      "  Recall: 0.6846\n",
      "  F1-Score: 0.6619\n",
      "\n",
      "Class: RIGHT\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-Score: 0.0000\n",
      "\n",
      "Class: CENTER\n",
      "  Precision: 0.5880\n",
      "  Recall: 0.8185\n",
      "  F1-Score: 0.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np  # Add numpy import for array operations\n",
    "\n",
    "def test_model_and_store_predictions(model, data_loader, device, id2label, output_csv=\"predictions.csv\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Testing\"):\n",
    "            # Move batch to GPU/CPU\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            document_id = batch[\"document_id\"]\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Collect predictions and true labels\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_ids.extend(document_id.cpu().numpy())  # Save the unique identifier for each record\n",
    "\n",
    "    # Create DataFrame to store predictions along with the actual data\n",
    "    predictions_df = pd.DataFrame({\n",
    "        \"document_id\": all_ids,\n",
    "        \"True_Label\": all_labels,\n",
    "        \"Pred_Label\": all_preds\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    predictions_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Predictions saved to {output_csv}\")\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "\n",
    "    # Per-class accuracy\n",
    "    per_class_accuracy = {}\n",
    "    for class_idx in range(len(id2label)):\n",
    "        # True positives for this class\n",
    "        true_positive = np.sum((np.array(all_preds) == class_idx) & (np.array(all_labels) == class_idx))\n",
    "        # Total instances of this class in the dataset\n",
    "        total_class_instances = np.sum(np.array(all_labels) == class_idx)\n",
    "        per_class_accuracy[id2label[class_idx]] = true_positive / total_class_instances if total_class_instances > 0 else 0.0\n",
    "\n",
    "    # Prepare and print results\n",
    "    print(\"\\nTest Results\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print metrics for each class\n",
    "    class_metrics = {}\n",
    "    for idx, label in id2label.items():\n",
    "        class_metrics[label] = {\n",
    "            \"Accuracy\": per_class_accuracy[label],\n",
    "            \"Precision\": precision[idx],\n",
    "            \"Recall\": recall[idx],\n",
    "            \"F1-Score\": f1[idx],\n",
    "        }\n",
    "        print(f\"\\nClass: {label}\")\n",
    "        print(f\"  Accuracy: {per_class_accuracy[label]:.4f}\")\n",
    "        print(f\"  Precision: {precision[idx]:.4f}\")\n",
    "        print(f\"  Recall: {recall[idx]:.4f}\")\n",
    "        print(f\"  F1-Score: {f1[idx]:.4f}\")\n",
    "\n",
    "    return accuracy, class_metrics\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Call the test function and store the predictions\n",
    "print(\"\\nEvaluating on Test Set\")\n",
    "test_accuracy, test_class_metrics = test_model_and_store_predictions(model, test_loader, device, id2label)\n",
    "\n",
    "# After saving predictions to CSV, you can use pandas to compute metrics or analyze the data\n",
    "# Example: Loading the CSV and computing overall metrics\n",
    "predictions_df = pd.read_csv(\"predictions.csv\")\n",
    "accuracy = accuracy_score(predictions_df[\"True_Label\"], predictions_df[\"Pred_Label\"])\n",
    "precision, recall, f1, support = precision_recall_fscore_support(predictions_df[\"True_Label\"], predictions_df[\"Pred_Label\"], average=None)\n",
    "\n",
    "# Print metrics from CSV\n",
    "print(\"\\nTest Results from CSV\")\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "for idx, label in id2label.items():\n",
    "    print(f\"\\nClass: {label}\")\n",
    "    print(f\"  Precision: {precision[idx]:.4f}\")\n",
    "    print(f\"  Recall: {recall[idx]:.4f}\")\n",
    "    print(f\"  F1-Score: {f1[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    True_Label  Pred_Label  Count\n",
      "0          0.0           0   2256\n",
      "4          1.0           1   2974\n",
      "11         3.0           3   3856\n"
     ]
    }
   ],
   "source": [
    "preds = pd.read_csv(\"predictions.csv\")\n",
    "preds.groupby(\"True_Label\").count()\n",
    "\n",
    "# Group by True_Label and Pred_Label to count occurrences of each combination\n",
    "group_counts = preds.groupby(['True_Label', 'Pred_Label']).size().reset_index(name='Count')\n",
    "\n",
    "# Print the counts of matching labels\n",
    "matching_counts = group_counts[group_counts['True_Label'] == group_counts['Pred_Label']]\n",
    "print(matching_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>True_Label</th>\n",
       "      <th>Pred_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4348226</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4604594</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4585051</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4291624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4316093</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>4359340</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>4287042</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>4349037</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>4627595</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>4344294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id  True_Label  Pred_Label\n",
       "16       4348226         2.0           1\n",
       "26       4604594         2.0           1\n",
       "40       4585051         2.0           3\n",
       "57       4291624         2.0           3\n",
       "68       4316093         2.0           1\n",
       "..           ...         ...         ...\n",
       "830      4359340         2.0           0\n",
       "835      4287042         2.0           1\n",
       "846      4349037         2.0           3\n",
       "852      4627595         2.0           3\n",
       "857      4344294         2.0           1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[preds['True_Label']==2].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for UNDEFINED:\n",
      "Accuracy: 0.5801\n",
      "Precision: 0.6498\n",
      "Recall: 0.5801\n",
      "F1-Score: 0.6130\n",
      "\n",
      "Metrics for LEFT:\n",
      "Accuracy: 0.6846\n",
      "Precision: 0.6407\n",
      "Recall: 0.6846\n",
      "F1-Score: 0.6619\n",
      "\n",
      "Metrics for RIGHT:\n",
      "Accuracy: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "\n",
      "Metrics for CENTER:\n",
      "Accuracy: 0.8185\n",
      "Precision: 0.5880\n",
      "Recall: 0.8185\n",
      "F1-Score: 0.6844\n"
     ]
    }
   ],
   "source": [
    "# Access and process per-class metrics if needed\n",
    "for class_name, metrics in test_class_metrics.items():\n",
    "    print(f\"\\nMetrics for {class_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_lda_implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
